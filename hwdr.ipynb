{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuC4uTFJilzldNPj9TyNob",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShivaShirsath/hwdr/blob/master/hwdr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install flask-ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxLheix9Z8cN",
        "outputId": "14345f2a-0639-43cd-e53b-4150be07afd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.9/dist-packages (from flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from flask-ngrok) (2.25.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=0.8->flask-ngrok) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->flask-ngrok) (1.26.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->flask-ngrok) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->flask-ngrok) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6.0->Flask>=0.8->flask-ngrok) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HYmO7etYCYb",
        "outputId": "191ac8df-124a-4361-b1aa-0fe5209135b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Handwritten-Digit-Recognition-CNN-Flask-App-'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 42 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (42/42), 2.55 MiB | 4.96 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Prajwal10031999/Handwritten-Digit-Recognition-CNN-Flask-App-.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls\n",
        "%cd Handwritten-Digit-Recognition-CNN-Flask-App-\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNCmt7lWYIF_",
        "outputId": "59ebd1a0-2da1-4240-ae13-8a4c574692ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handwritten-Digit-Recognition-CNN-Flask-App-  sample_data\n",
            "/content/Handwritten-Digit-Recognition-CNN-Flask-App-\n",
            "app.py\t    config.py\t    README.md\t      templates    train.py\n",
            "app.yaml    digit_demo.gif  requirements.txt  test_app.py  utils.py\n",
            "checkpoint  digit.mp4\t    static\t      torch_serve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import base64\n",
        "import config\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from train import MnistModel\n",
        "import matplotlib.pyplot as plt\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "matplotlib.use('Agg')\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "\n",
        "MODEL = None\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "run_with_ngrok(app)\n",
        "\n",
        "\n",
        "\n",
        "class SaveOutput:\n",
        "    def __init__(self):\n",
        "        self.outputs = []\n",
        "\n",
        "    def __call__(self, module, module_in, module_out):\n",
        "        self.outputs.append(module_out)\n",
        "\n",
        "    def clear(self):\n",
        "        self.outputs = []\n",
        "\n",
        "\n",
        "def register_hook():\n",
        "    save_output = SaveOutput()\n",
        "    hook_handles = []\n",
        "\n",
        "    for layer in MODEL.modules():\n",
        "        if isinstance(layer, torch.nn.modules.conv.Conv2d):\n",
        "            handle = layer.register_forward_hook(save_output)\n",
        "            hook_handles.append(handle)\n",
        "    return save_output\n",
        "\n",
        "\n",
        "def module_output_to_numpy(tensor):\n",
        "    return tensor.detach().to('cpu').numpy()\n",
        "\n",
        "\n",
        "def autolabel(rects, ax):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{0:.2f}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "def prob_img(probs):\n",
        "    fig, ax = plt.subplots()\n",
        "    rects = ax.bar(range(len(probs)), probs)\n",
        "    ax.set_xticks(range(len(probs)), (0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
        "    ax.set_ylim(0, 110)\n",
        "    ax.set_title('Probability % of Digit by Model')\n",
        "    autolabel(rects, ax)\n",
        "    probimg = BytesIO()\n",
        "    fig.savefig(probimg, format='png')\n",
        "    probencoded = base64.b64encode(probimg.getvalue()).decode('utf-8')\n",
        "    return probencoded\n",
        "\n",
        "\n",
        "def interpretability_img(save_output):\n",
        "    images = module_output_to_numpy(save_output.outputs[0])\n",
        "    with plt.style.context(\"seaborn-white\"):\n",
        "        fig, _ = plt.subplots(figsize=(20, 20))\n",
        "        plt.suptitle(\"Interpretability by Model\", fontsize=50)\n",
        "        for idx in range(16):\n",
        "            plt.subplot(4, 4, idx+1)\n",
        "            plt.imshow(images[0, idx])\n",
        "        plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "    interpretimg = BytesIO()\n",
        "    fig.savefig(interpretimg, format='png')\n",
        "    interpretencoded = base64.b64encode(\n",
        "        interpretimg.getvalue()).decode('utf-8')\n",
        "    return interpretencoded\n",
        "\n",
        "\n",
        "def mnist_prediction(img):\n",
        "    save_output = register_hook()\n",
        "    img = img.to(DEVICE, dtype=torch.float)\n",
        "    outputs = MODEL(x=img)\n",
        "\n",
        "    probs = torch.exp(outputs.data)[0] * 100\n",
        "    probencoded = prob_img(probs)\n",
        "    interpretencoded = interpretability_img(save_output)\n",
        "\n",
        "    _, output = torch.max(outputs.data, 1)\n",
        "    pred = module_output_to_numpy(output)\n",
        "    return pred[0], probencoded, interpretencoded\n",
        "\n",
        "\n",
        "@app.route(\"/process\", methods=[\"GET\", \"POST\"])\n",
        "def process():\n",
        "    data_url = str(request.get_data())\n",
        "    offset = data_url.index(',')+1\n",
        "    img_bytes = base64.b64decode(data_url[offset:])\n",
        "    img = Image.open(BytesIO(img_bytes))\n",
        "    img = img.convert('L')\n",
        "    img = img.resize((28, 28))\n",
        "    # img.save(r'templates\\image.png')\n",
        "    img = np.array(img)\n",
        "    img = img.reshape((1, 28, 28))\n",
        "    img = torch.tensor(img, dtype=torch.float).unsqueeze(0)\n",
        "\n",
        "    data, probencoded, interpretencoded = mnist_prediction(img)\n",
        "\n",
        "    response = {\n",
        "        'data': str(data),\n",
        "        'probencoded': str(probencoded),\n",
        "        'interpretencoded': str(interpretencoded),\n",
        "    }\n",
        "    return jsonify(response)\n",
        "\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def start():\n",
        "    return render_template(\"default.html\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL = MnistModel(classes=10)\n",
        "    MODEL.load_state_dict(torch.load(\n",
        "        'checkpoint/mnist.pt', map_location=DEVICE))\n",
        "    MODEL.to(DEVICE)\n",
        "    MODEL.eval()\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KphRYOSqYsd3",
        "outputId": "84e7e38b-cf36-462b-c535-e65e3fb159bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://c144-35-232-163-226.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/Mar/2023 12:35:31] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [16/Mar/2023 12:35:32] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9rv2YUHXY3x-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}